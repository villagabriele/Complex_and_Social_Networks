---
title: "LAB06 CSN"
author: "Domenico Azzarito, Gabriele Villa"
date: "2025-12-07"
output:
  html_document: default
  pdf_document: default
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
```

# Community detection

## Import libraries

```{r}
library(igraph)
library(igraphdata)
library(clustAnalytics)

#install.packages("randomcoloR")   # run once
library(randomcoloR)
```

## Jaccard similarity function

```{r}
jaccard_sim = function(cluster1, cluster2) {
  
  # Function to compute the Jaccard similarity matrix between two clusterings
  # Inputs:
  #   - cluster1: first clustering (igraph clustering object)
  #   - cluster2: second clustering (igraph clustering object)
  # Outputs:
  #   - m: Jaccard similarity matrix
  
  c1 = membership(cluster1)
  c2 = membership(cluster2)
  l1 = length(cluster1)
  l2 = length(cluster2)
  m = matrix(nrow = l1, ncol = l2)
  for (i in 1:l1) {
    for (j in 1:l2) {
      set1 = names(c1[unname(c1==i)])
      set2 =  names(c2[unname(c2==j)])
      int = length(intersect(set1, set2))
      uni = length(union(set1, set2))
      
      jacc = int / uni
      
      m[i, j] = jacc
    }
  }
  dimnames(m) = list(1:l1, 1:l2)
  return (m)
}
```

## Match clusters function

```{r}
match_clusters <- function(JS, name1, name2) {

  # Function to match clusters based on Jaccard similarity matrix. 
  # It chooses for each cluster in the first clustering the cluster in the
  # second clustering with the highest Jaccard similarity.
  # Inputs:
  #   - JS: Jaccard similarity matrix with rows as clusters of the first
  #         clustering and columns as clusters of the second clustering
  #   - name1: name of the first clustering
  #   - name2: name of the second clustering
  # Outputs:
  #   - max_jaccard: named vector of maximum Jaccard similarities 
  #                  for each cluster in the first clustering

  n_clusters <- nrow(JS)
  
  max_jaccard <- numeric(n_clusters)
  names_vector <- character(n_clusters)
  
  for (i in 1:n_clusters) {
    j <- which.max(JS[i, ])
    max_jaccard[i] <- JS[i, j]
    names_vector[i] <- paste0("(", name1, ".", i, ",", name2, ".", j, ")")
  }
  
  names(max_jaccard) <- names_vector
  
  return(max_jaccard)
}
```

## Weighted mean

```{r}
Wmean <- function(MC, cluster1, cluster2, JS = NULL) {
  
  # Function to compute the weighted mean of maximum Jaccard similarities
  # Inputs:
  #   - MC: named vector of maximum Jaccard similarities for each cluster
  #   - cluster1: first clustering (igraph clustering object)
  #   - cluster2: second clustering (igraph clustering object)
  #   - JS: (optional) Jaccard similarity matrix between the two clusterings
  # Outputs:
  #   - weighted_mean: weighted mean of maximum Jaccard similarities
  
  c1 <- membership(cluster1)
  c2 <- membership(cluster2)
  n_total <- length(c1)
  
  n_clusters <- length(MC)
  
  if (is.null(JS)) {
    JS <- jaccard_sim(cluster1, cluster2)
  }
  matched_indices <- apply(JS, 1, which.max)
  
  # Compute weights
  weights <- vapply(
    seq_len(n_clusters),
    function(i) length(which(c1 == i)) / n_total,
    numeric(1)
  )
  
  weighted_mean <- sum(MC * weights)
  
  return(weighted_mean)
}
```

## Evaluation of significance

### Functions for evaluate the significance and found the ground truth

```{r}
compute_scores <- function(network, clust.algorithms, random.alg.bool, choosen.scores, higher.is.better, iter = 100){
  
  # Function to compute significance scores for clustering algorithms on a network, 
  # applying Min-Max normalization and computing an aggregated score.
  # Inputs:
  #   - network: igraph object
  #   - clust.algorithms: list of algorithm functions
  #   - random.alg.bool: logical vector (TRUE if algorithm is stochastic)
  #   - choosen.scores: character vector of score names (must match clustAnalytics output names)
  #   - higher.is.better: logical vector, same length as choosen.scores: 
  #                       TRUE if high metric is good 
  #                       FALSE if low metric is good
  #   - iter: number of iterations for stochastic algorithms
  # Outputs:
  #   - final.df: data frame with raw scores, normalized scores, and the combined rank score
  
  # Collect raw scores for all algorithms
  raw.results.list <- list()
  
  for(i in 1:length(clust.algorithms)){
    alg <- clust.algorithms[[i]]
    alg.name <- names(clust.algorithms)[i]
    
    if(random.alg.bool[i]){
      # Stochastic algorithm with multiple iterations
      temp.matrix = matrix(0, nrow = iter, ncol = length(choosen.scores))
      colnames(temp.matrix) = choosen.scores
      
      for(j in 1:iter){
        eval_out <- evaluate_significance(network, alg_list = c(alg), gt_clustering = NULL)
        
        # Ensure we only pick the chosen scores columns
        temp.matrix[j, ] <- as.numeric(eval_out[choosen.scores,])
      }
      
      mean.scores <- colMeans(temp.matrix, na.rm = TRUE)
      raw.results.list[[alg.name]] <- mean.scores
      
    } else {
      # Deterministic algorithm
      eval_out <- evaluate_significance(network, alg_list = c(alg), gt_clustering = NULL)
      scores <- as.numeric(eval_out[choosen.scores,])
      names(scores) <- choosen.scores
      raw.results.list[[alg.name]] <- scores
    }
  }
  
  # Create data frame from raw results
  scores.df <- do.call(rbind, raw.results.list)
  scores.df <- as.data.frame(scores.df)
  colnames(scores.df) <- choosen.scores
  
  # Create a copy for normalized values for Min-Max normalization and aggregation
  norm.df <- scores.df 
  
  for(k in 1:length(choosen.scores)){
    metric.name <- choosen.scores[k]
    values <- scores.df[[metric.name]]
    
    min.val <- min(values, na.rm = TRUE)
    max.val <- max(values, na.rm = TRUE)
    denominator <- max.val - min.val
    
    # Handle edge case where max == min (avoid division by zero)
    if(denominator == 0){
      norm.df[[metric.name]] <- 1 # It's arbitrary since all values are the same (could also be 0)
    } else {
      if(higher.is.better[k] == TRUE){
        # High is Best: (x - min) / (max - min)
        norm.df[[metric.name]] <- (values - min.val) / denominator
      } else {
        # Low is Best: (max - x) / (max - min)
        norm.df[[metric.name]] <- (max.val - values) / denominator
      }
    }
  }
  
  # Compute aggregated score as the mean of normalized scores
  scores.df$aggregated.score <- rowMeans(norm.df, na.rm = TRUE)
  
  return(scores.df)
}
```

```{r}
choose_ground_truth <- function(score.df){

  # Function to choose the best clustering algorithm based on weighted scores
  # Inputs:
  #   - score.df: data frame with scores for each algorithm
  # Outputs:
  #   - best.algorithm: name of the function representing the best clustering algorithm

  # Extract the weighted scores
  weighted.scores = score.df[,"aggregated.score"]

  # Find the algorithm with the highest weighted score
  best.index = which.max(weighted.scores)
  best.algorithm = rownames(score.df)[best.index]
  return(best.algorithm)
}
```

```{r}
compute_jaccard <- function(network, ground.truth, clust.algorithms, random.alg.bool, iter = 100, memb.names = NULL){
  gt.static <- ground.truth
  if (! is.null(memb.names)) {
    names(gt.static$membership) <- memb.names
  }

  n.gt.clusters <- length(gt.static)

  global.jaccard.list <- list()
  local.jaccard.list <- list() 

  det.clusterings <- list()
  ind.det <- which(random.alg.bool == FALSE)
  for(i in ind.det){
    alg <- clust.algorithms[[i]]
    alg.name <- names(clust.algorithms)[i]
    clust <- alg(network)
    if (! is.null(memb.names)) {
      names(clust$membership) <- memb.names
    }
    det.clusterings[[alg.name]] <- clust
  }
  
  for(i in seq_along(clust.algorithms)){
    alg <- clust.algorithms[[i]]
    alg.name <- names(clust.algorithms)[i]
    is.alg.random <- random.alg.bool[i]

    if(is.alg.random){
      temp.jaccard <- numeric(iter)
      all.matchings <- vector("list", n.gt.clusters)
      for(k in seq_len(n.gt.clusters)) {
        all.matchings[[k]] <- list(names = character(0), values = numeric(0))
      }

      for(j in seq_len(iter)){
        clustering <- alg(network)
        if (!is.null(memb.names)) {
          names(clustering$membership) <- memb.names
        }
        current.gt <- gt.static

        js.matrix <- jaccard_sim(current.gt, clustering)
        js.matched <- match_clusters(js.matrix, 'GT', alg.name)
        wm <- Wmean(js.matched, current.gt, clustering, js.matrix)

        temp.jaccard[j] <- wm
        for(k in seq_len(n.gt.clusters)) {
          match.name <- names(js.matched)[k]
          match.value <- js.matched[k]
          all.matchings[[k]]$names <- c(all.matchings[[k]]$names, match.name)
          all.matchings[[k]]$values <- c(all.matchings[[k]]$values, match.value)
        }
      }

      global.jaccard.list[[alg.name]] <- mean(temp.jaccard)

      final.local <- numeric(n.gt.clusters)
      final.names <- character(n.gt.clusters)

      for(k in seq_len(n.gt.clusters)) {
        unique.names <- unique(all.matchings[[k]]$names)
        best.mean <- -Inf
        best.name <- ""
        for(uname in unique.names) {
          idx <- which(all.matchings[[k]]$names == uname)
          mean.value <- mean(all.matchings[[k]]$values[idx])
          if(mean.value > best.mean) {
            best.mean <- mean.value
            best.name <- uname
          }
        }
        final.local[k] <- best.mean
        final.names[k] <- best.name
      }
      
      names(final.local) <- final.names
      local.jaccard.list[[alg.name]] <- final.local

    } else {
      clustering <- det.clusterings[[alg.name]]
      current.gt <- gt.static

      js.matrix <- jaccard_sim(current.gt, clustering)
      js.matched <- match_clusters(js.matrix, 'GT', alg.name)
      wm <- Wmean(js.matched, current.gt, clustering, js.matrix)

      global.jaccard.list[[alg.name]] <- wm
      local.jaccard.list[[alg.name]] <- js.matched
    }
  }

  return(list(
    global = global.jaccard.list, 
    local = local.jaccard.list
  ))
}
```

### Karate Dataset

```{r}
set.seed(123)
data(karate,package="igraphdata")
karate = upgrade_graph(karate)

gt_membership.ka = V(karate)$Faction
gt_karate = make_clusters(karate, membership = gt_membership.ka)
names(gt_karate$membership) <- V(karate)$name

clusterings.list <- list(Louvain = cluster_louvain, 
                         "label prop" = cluster_label_prop, 
                         walktrap = cluster_walktrap,
                         ebc = cluster_edge_betweenness)

scores.karate <- compute_scores(karate, 
                         clust.algorithms = clusterings.list,
                         random.alg.bool = c(TRUE, TRUE, FALSE, FALSE), 
                         choosen.scores = c("modularity", "conductance", "clustering coef", "expansion"), higher.is.better = c(T, F, T, F), iter = 100)

jaccard.similarity.karate <- compute_jaccard(karate, gt_karate, 
                          clust.algorithms = clusterings.list,
                          random.alg.bool = c(TRUE, TRUE, FALSE, FALSE), iter = 100)
```

```{r}
print(scores.karate)
```

```{r}
print(jaccard.similarity.karate$global)
```

```{r}
print(jaccard.similarity.karate$local)
```

#### Visualization of Karate clusters

```{r}
plot_with_legend <- function(graph, clustering_membership, layout, vertex.size, edge.width = 0.3) {
  
  # Identify unique clusters in order
  unique_clusters <- sort(unique(clustering_membership))
  n_clusters <- length(unique_clusters)
  
  # Define color palette (use igraph default or a custom one)
  palette <- distinctColorPalette(max(8, n_clusters))[1:n_clusters]
  
  # Map colors to clusters
  color_mapping <- palette[match(clustering_membership, unique_clusters)]
  
  # Plot the graph
  plot(graph, 
     vertex.size = vertex.size, 
     vertex.label = clustering_membership,
     vertex.label.color = "black",
     vertex.label.cex = 1.2,
     vertex.label.font = 5,
     edge.width = edge.width,
     layout = layout, 
     vertex.color = color_mapping,
     main = "")
}
```

```{r message=FALSE, warning=FALSE}
set.seed(1234)
l.k <- layout_with_fr(karate)  # For fixed layout

louvain_memb <- membership(cluster_louvain(karate))
plot_with_legend(karate, louvain_memb, l.k, 10, 1)

labelprop_memb <- membership(cluster_label_prop(karate))
plot_with_legend(karate, labelprop_memb, l.k, 10, 1)

walktrap_memb <- membership(cluster_walktrap(karate))
plot_with_legend(karate, walktrap_memb, l.k, 10, 1)

ebc_memb <- membership(cluster_edge_betweenness(karate))
plot_with_legend(karate, ebc_memb, l.k, 10, 1)

gt_memb <- V(karate)$Faction
plot_with_legend(karate, gt_memb, l.k, 10, 1)
```

### Synthetic network

We have to build a network with 200 nodes, 800 edges, 4 communities and scale-free degree distribution

```{r}
set.seed(123)
B = matrix(c(
  1.0, 0.1, 0.1, 0.1,
  0.1, 1.0, 0.1, 0.1,
  0.1, 0.1, 1.0, 0.1,
  0.1, 0.1, 0.1, 1.0
), ncol = 4, byrow = TRUE)

p = c(0.25, 0.25, 0.25, 0.25)

G = barabasi_albert_blocks(m = 4, p = p, B = B, t_max = 200, type = "Hajek", sample_with_replacement = FALSE)
```

```{r}
set.seed(123)
gt_membership.ba = V(G)$label
gt_ba = make_clusters(G, membership = gt_membership.ba)
names(gt_ba$membership) <- 1:200

scores.ba <- compute_scores(G, 
                         clust.algorithms = clusterings.list,
                         random.alg.bool = c(TRUE, TRUE, FALSE, FALSE), 
                         choosen.scores = c("modularity", "conductance", "clustering coef", "expansion"), higher.is.better = c(T, F, T, F), iter = 100)

jaccard.similarity.ba <- compute_jaccard(G, gt_ba, 
                          clust.algorithms = clusterings.list,
                          random.alg.bool = c(TRUE, TRUE, FALSE, FALSE), iter = 100, memb.names = 1:200)
```

```{r}
print(scores.ba)
```

```{r}
print(jaccard.similarity.ba$global)
```

```{r}
print(jaccard.similarity.ba$local)
```

#### Visualization of Synthetic BA blocks clusters

```{r}
set.seed(123)
l.ba <- layout_with_fr(G)

louvain_memb_ba <- membership(cluster_louvain(G))
plot_with_legend(G, louvain_memb_ba, l.ba, 8)

labelprop_memb_ba <- membership(cluster_label_prop(G))
plot_with_legend(G, labelprop_memb_ba, l.ba, 8)

walktrap_memb_ba <- membership(cluster_walktrap(G))
plot_with_legend(G, walktrap_memb_ba, l.ba, 8)

ebc_memb_ba <- membership(cluster_edge_betweenness(G))
plot_with_legend(G, ebc_memb_ba, l.ba, 8)

gt_memb_ba <- V(G)$label
plot_with_legend(G, gt_memb_ba, l.ba, 8)
```

### ENRON network

```{r}
data(enron,package="igraphdata")
enron.simple <- simplify(
  as.undirected(enron, mode = "collapse"),
  edge.attr.comb = list(weight = "sum")
)

set.seed(123)
scores.enron <- compute_scores(enron.simple, 
                         clust.algorithms = clusterings.list,
                         random.alg.bool = c(TRUE, TRUE, FALSE, FALSE), 
                         choosen.scores = c("modularity", "conductance", "clustering coef", "expansion"),
                          higher.is.better = c(T, F, T, F), iter = 100)

choose_ground_truth(scores.enron)
```

```{r}
set.seed(123)
gt_enron <- cluster_louvain(enron.simple)
names(gt_enron$membership) <- 1:vcount(enron.simple)

enron.clusterings.list <- list(
  "label prop" = cluster_label_prop, 
  walktrap = cluster_walktrap,
  ebc = cluster_edge_betweenness
)

jaccard.similarity.enron <- compute_jaccard(enron.simple, gt_enron, 
                          clust.algorithms = enron.clusterings.list,
                          random.alg.bool = c(TRUE, FALSE, FALSE), iter = 100,
                          memb.names = 1:vcount(enron.simple))
```

```{r}
print(scores.enron)
```

```{r}
print(jaccard.similarity.enron$global)
```

```{r}
print(jaccard.similarity.enron$local)
```

#### Visualization of ENRON clusters

```{r}
set.seed(123)
l.enron <- layout_with_kk(enron.simple)

louvain_memb_enron <- membership(gt_enron)
plot_with_legend(enron.simple, louvain_memb_enron, l.enron, 6)

labelprop_memb_enron <- membership(cluster_label_prop(enron.simple))
plot_with_legend(enron.simple, labelprop_memb_enron, l.enron, 6)

walktrap_memb_enron <- membership(cluster_walktrap(enron.simple))
plot_with_legend(enron.simple, walktrap_memb_enron, l.enron, 6)

ebc_memb_enron <- membership(cluster_edge_betweenness(enron.simple))
plot_with_legend(enron.simple, ebc_memb_enron, l.enron, 6)

```

### Network of our choice

```{r}
# Load UKfaculty network from igraphdata
data(UKfaculty, package = "igraphdata")

# Convert to simple weighted graph (it's a multigraph)
ukfaculty_graph <- as.undirected(UKfaculty, mode = "collapse")
ukfaculty_graph <- simplify(ukfaculty_graph, edge.attr.comb = list(weight = "sum"))

# Check num of nodes and edges
vcount(ukfaculty_graph)
ecount(ukfaculty_graph) 


set.seed(123)
scores.ukfaculty <- compute_scores(
  ukfaculty_graph,
  clust.algorithms = clusterings.list,
  random.alg.bool = c(TRUE, TRUE, FALSE, FALSE),
  choosen.scores = c("modularity", "conductance", "clustering coef", "expansion"),
  higher.is.better = c(TRUE, FALSE, TRUE, FALSE),
  iter = 100
)

best_alg <- choose_ground_truth(scores.ukfaculty)
cat("Best algorithm:", best_alg, "\n")
```

```{r}
set.seed(123)

gt_ukfaculty <- cluster_walktrap(ukfaculty_graph) 
names(gt_ukfaculty$membership) <- 1:vcount(ukfaculty_graph)

ukfaculty.clusterings.list <- list(
  Louvain = cluster_louvain,
  "label prop" = cluster_label_prop,
  ebc = cluster_edge_betweenness
)

jaccard.similarity.ukfaculty <- compute_jaccard(ukfaculty_graph, gt_ukfaculty, 
                          clust.algorithms = ukfaculty.clusterings.list,
                          random.alg.bool = c(TRUE, TRUE, FALSE), iter = 100, 
                          memb.names = 1:vcount(ukfaculty_graph))
```

```{r}
print(scores.ukfaculty)
```

```{r}
print(jaccard.similarity.ukfaculty$global)
```

```{r}
print(jaccard.similarity.ukfaculty$local)
```

#### Visualization of UK Faculty Graph

```{r}
set.seed(123)
l.ukfaculty <- layout_with_kk(ukfaculty_graph)

louvain_memb_ukfaculty <- membership(cluster_louvain(ukfaculty_graph))
plot_with_legend(ukfaculty_graph, louvain_memb_ukfaculty, l.ukfaculty, 10, 0.8)

labelprop_memb_ukfaculty <- membership(cluster_label_prop(ukfaculty_graph))
plot_with_legend(ukfaculty_graph, labelprop_memb_ukfaculty, l.ukfaculty, 10, 0.8)

walktrap_memb_ukfaculty <- membership(gt_ukfaculty)
plot_with_legend(ukfaculty_graph, walktrap_memb_ukfaculty, l.ukfaculty, 10, 0.8)

ebc_memb_ukfaculty <- membership(cluster_edge_betweenness(ukfaculty_graph))
plot_with_legend(ukfaculty_graph, ebc_memb_ukfaculty, l.ukfaculty, 10, 0.8)

```

## Save outputs to RData files

```{r}
# Ensure data directory exists
if (!dir.exists("data")) dir.create("data", recursive = TRUE)

# Karate network artifacts
save(karate, gt_karate, scores.karate, jaccard.similarity.karate,
     file = file.path("data", "karate_results.RData"))

# Synthetic Barabási–Albert blocks network artifacts
save(G, gt_ba, scores.ba, jaccard.similarity.ba,
     file = file.path("data", "synthetic_ba_results.RData"))

# ENRON network artifacts
save(enron.simple, gt_enron, scores.enron, jaccard.similarity.enron,
     file = file.path("data", "enron_results.RData"))

# UKFaculty network artifacts
save(ukfaculty_graph, gt_ukfaculty, scores.ukfaculty, jaccard.similarity.ukfaculty,
    file = file.path("data", "ukfaculty_results.RData"))
```
